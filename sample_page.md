## Extract Transform Load Pipeline

**Project description:**Built a basic ETL pipeline that read data from a source, transformed it and then loaded the output into a prescribed location.Pandas and Amazon Simple Storage Service(S3) were used for this project.A virtual environment was setup,the dataset was downloaded from the amazon s3 bucket, read with pandas and companies without domain names filtered out. The resulting dataframe was converted to parquet and json and uploaded to specified s3 bucket

[Click here](https://github.com/Adutwumwaa/Blossom-Fall-2019-Data-Engineering/tree/master/Project1)
 


