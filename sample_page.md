## BASIC Extract Transform Load Pipeline

**Project description:**Built a basic ETL pipeline that read data from a source, transformed it and then loaded the output into a prescribed location.Pandas and Amazon Simple Storage Service(S3) were used for this project.A virtual environment was setup,the dataset was downloaded from the amazon s3 bucket, read with pandas and companies without domain names filtered out. The resulting dataframe was converted to parquet and json and uploaded to specified s3 bucket

[Click here](https://github.com/Adutwumwaa/Blossom-Fall-2019-Data-Engineering/tree/master/Project1)
 

### 1. Suggest hypotheses about the causes of observed phenomena

Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. 

```javascript
if (isAwesome){
  return true
}
```

### 2. Assess assumptions on which statistical inference will be based

```javascript
if (isAwesome){
  return true
}
```

### 3. Support the selection of appropriate statistical tools and techniques

<img src="images/dummy_thumbnail.jpg?raw=true"/>

### 4. Provide a basis for further data collection through surveys or experiments

Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. 

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).
